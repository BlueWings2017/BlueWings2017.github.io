---
layout: post
title:  "CleanCodeSb"
author: 장수빈
date:   2023-04-14
category: TeamB
icon: cleancode
keywords: tag1, tag2
preview: 0
---

# 클린코드: 모든 개발자가 실무를 위해 꼭 알아야 할 기본기 클래스         
              
## 파이썬 설치
---
: Python 버전을 다양하게 사용할 수 있도록 돕는 pyenv와 프로젝트 별로 의존성을 관리할 수 있도록 돕는 virtualenv나 anaconda가 많이 사용됨

- add python -> 환경변수 설치
- windows python 설치 확인 명령어 : python --version 
- 에러 Failed to create a virtual environment -> 버전 확인 후 22.1 버전으로 재설치


## 파이썬 문법 학습 가이드
---
>//name값 받아오기
def print_hi(name):
    print(f'Hi, {name}')  # Press Ctrl+F8 to toggle the breakpoint.

>def hello():
    print('hello')

>//출력
if __name__ == '__main__':
    print_hi('PyCharm')
    hello()


- Git 작업공간
: git의 4가지 작업공간

사진으로 대체(바탕화면, git)

- work space
:일반적으로 작업하는 공간. git을 쓰기 이전 처음 상태.
git add 명령어 이전에 변경 사항은 work space에 기록됨.

- index
한 번 index에 올라갔던 파일들은 git에서 계속해서 추적됨

- local repository
커밋이 된 작업물들이 이 공간에 기록됨
git commit을 통해 index의 파일들이 이곳으로 옴

- remote repository
git push, fetch, pull을 통해 local repository와 remote repository를 동기 할 수 있음.


>기본 동작 흐름
: work space -> index -> local repository -> remote repository


- branch
: 사용자가 독립적으로 작업을 진행할 수 있도록 돕는 작업 흐름

>작업 흐름
(1) 각자 작업할 브랜치 생성
(2) 자신의 즈랜치에서 작업
(3) 깃 호스팅 서버(github)를 쓰지 않는 경우엔 아래 흐름을 따름

> remote repository에 자신의 브랜치 push
> remote repository에서 메인 브랜치로 pull request
> 협업하는 다른 개발자에게 리뷰 받음
> 리뷰 및 합의 이후에는 메인 브랜치에 merge


- 이전 commit 내역, 변경사항 확인
: git log, 로그 확인

- git log --online --decorate --graph
: 그래프 형태로 로그 확인

- git show
: 가장 최신의 내용을 확인

- git show HEAD^^(HEAD~2)
: 현재로부터 2번째 전에 있는 커밋을 기준으로 확인

- git reset --hard HEAD^^
: hard는 아예 삭제함 -> 커밋이 모두 날라간 경우 복구
-> git reflog --hard (기준 로그)


## 변경사항, 커밋 초기화
---
 : git restore는 git reset --hard HEAD와 비슷한 역할을 함.

- git revert (커밋 시점)
: 메시지 수정 가능

- rebase --interactive
: 커밋 내역 조작


## 변경사항 임시저장
---
- git stash
: 수정사항을 임시저장
ex) git stash -m '커밋 메세지(변경사항)'

- git stash list
: 임시 저장 한 리스트 확인

- git stash pop과 apply
: 스태시한 내역을 저장하는 스택 공간에서 내역을 제거하는지의 여부로 차이점이 갈림. pop은 제거, apply는 스택에서 작업 내역을 빼지 않기 때문에 git stash list로 봐도 작업 내역이 그대로 남아있음
-> 여전히 스택에 남아있기 때문에 다른 곳에서 넣어둔 작업내역을 재사용 가능 


## 이전에 쌓인 커밋 변경
---
>1) git commit --amend: 현재 작업 중인 커밋을 간단히 수정
-커밋 메시지의 수정을 필요로 하지 않는 경우엔 '--no-edit' 옵션을 붙여준다.
+pick: 별다른 변경 사항 없이 그냥 커밋으로 둠
+edit: 해당 커밋 내용과 커밋 메시지 변경
+reword: 해당 커밋의 메시지만 변경
+drop: 해당 커밋을 제거

>2) git rebase --interactive: 커밋 일부를 수정하거나 변경
-과거 커밋 히스토리를 변경할 수 있는 기능 '--interactive'

>3) git push origin main --force(f): 로컬에서 리모트로 해당 브랜치의 변경사항을 강제로 덮음

## 브랜치 merge시에 커밋을 남기기 싫을 때
---
: 브랜치 관리 전략에 따라 다른 merge 방식을 사용함

- 1)기본 merge
 : git merge (브랜치명)
-> merge commit을 통해 명시적으로 브랜치의 병합이 있었다는 걸 표시해주고 싶을 때 많이 활용

- 2)Squash & merge
: git merge (브랜치명) --squash
-> merge commit을 만들지 않고 변경사항만 병합. 커밋 구조를 깔끔하게 유지할 수 있으나 롤백 처리 시 커밋을 한 번에 처리할 수 없게 됨.

- 3)Rebase & merge
: git rebase (브랜치명)
-> merge commit을 만들지 않고, merge되는 브랜치의 모든 커밋 내역을 그대로 가져옴. 코드는 깔끔하나 브랜치의 병합 히스토리가 명시적으로 잘 남지 않아 히스토리를 추적할 때 불편할 수 있음.


## 다른 브랜치에 있는 커밋을 내 브랜치로 가져오기
---
: git cherry-pick (가져올 커밋)


## 실전 충돌 다루기
---
>1) Merge 과정에서 충돌이 났을 때
: conflict marker를 기준으로 맞는 라인을 남겨둠.

>2) 하나의 브랜치를 함께 사용하다가 충돌이 나는 경우
: git pull origin (브랜치명) --rebase
->pull을 할 때 rebase 옵션을 줘서 커밋의 순서를 일정하게 보장하여 push를 진행


## Git의 전략적 사용
---
: gitflow(+Github-flow, Gitlab-flow 등도 있음)

>프로젝트 개발 사이클
>(1) 필요한 기능을 분석, 정의하고 개발
>(2) 개발이 완료되면 테스트 환경에 배포
>(3) 통합 테스트를 진행하며 버그 등 문제가 없는지 확인
>(4) 문제가 있으면 이를 수정하고 (2)~(3)의 과정 거침
>(5) 테스트 완료 후에 최종적으로 운영 환경에 배포
>(6) 최종 배포 후 버그를 발견하면 수정하여 업데이트된 프로젝트를 배포

- Gitflow 브랜치 전략
: Gitflow는 master, develop, feature, release, hotfix의 5가지 브랜치를 두도록 약속함

>1) master: 운영 환경에 최종 배포가 되는 프로젝트를 담는 브랜치 
>2) develop: 기능 개발을 완료한 프로젝트를 담는 브랜치
>3) feature: 필요한 기능을 작업, 'feature/기능'으로 이름을 지음. develop 브랜치로부터 파생되며, 해당 브랜치에서 작업이 완료되면 develop 브랜치로 merge됨
>4) release: 최종 배포 전 통합 테스트를 할 프로젝트를 담음
>5) hotfix: 운영 환경 중 발견된 심각한 버그를 수정할 때 사용하는 브랜치


## 클린코드 - 네이밍
---
: 코딩을 하면서 이름을 지을 때 대표적인 컨벤션으로 snake_case(언더 바), camelCase(낙타표기법), PascalCase(처음부터 대문자), kebab-case(바)가 있음

>1) snake_case: Python, Ruby
>2) camelCase: Java, Javascript 
>3) PascalCase: 대부분의 프로그래밍 언어에서 클래스를 네이밍할 때 사용함
>4) kebab-case: HTML Element를 표현할 때 사용

- 변수와 상수
:일반적으로 함수와 메서드를 네이밍할 때는 동사 혹은 형용사 구문형태로 지음
ex) def send_data();, def input_is_valid();

- 클래스
: 클래스명은 명사 구문형태로 지음
ex) Class Client;

- Tips
-구체적이고 명시적으로 적을 것
ex) Dt, data이지만 혼자만 알아봄. B, idx=index
-불필요한 표현은 제거할 것

## 클린 코드 - 주석, 포맷팅
---
: 모든 내용을 주석으로 넣게 되면 코드가 지저분할 수 있음. 대부분은 좋은 name을 설정함으로써 해결 가능

## 1) 주석
: 법적인 정보를 담을 때
ex) Copyright 2021...
>의도를 명확히 설명할 때
>중요성을 강조할 때
>결과를 경고할 때

>관용적으로 사용되는 키워드
-TODO: 당장은 아니지만 다음에 해야할 때
-FIXME: 치명적인 에러를 발생하느 코드는 아니나 수정해야 할 때
-XXX: 더 생각해볼 필요가 있을 때

## 2) 포맷팅

2-1) Vertical Formatting
- 한 파일에 코드를 다 넣지 말고, 개념에 맞게 파일을 나눠서 사용
- 다른 개념의 코드는 Spacing으로 분리
- 비슷한 개념의 코드는 붙여서 사용

2-2) Horizontal Formatting
- 한 줄에 코드를 다 넣기보단 변수 등을 활용해 가독성 높이기
- 네이밍 잘해서 길이 줄이기


## 클린 코드 - 함수의 원칙 4가지
---

>1) 함수의 역할은 하나만 할 수 있도록 하기(SRP)
: 함수의 역할이 많아지면 오류가 날 가능성이 커지고 가독성이 떨어짐. 또한 테스트 진행에 어려움이 생김

>2) 반복하지 말기(DRY)
: 관심사를 잘 분리하고, 의존성을 줄이기 위해 반복되는 코드를 하나의 함수로 만들어 사용

>3) 파라미터 수는 적게 유지
>4) 사이드 이펙트를 잘 핸들링
- 사이드 이펙트는 함수가 실행됐을 때 함수 이외의 어떤 것들에 변화를 주는 것을 의미. 핸들링을 잘 하지 못하면 예측 못할 문제가 생길 수 있음.

- 핸들링을 잘 하는 법
 4-1) 코드를 통해 충분히 예측할 수 있도록 네이밍을 잘하는 것
-update, set 같은 직관적인 prefix를 붙여서 사이드 이펙트가 있을 수 있음을 암시.
 4-2) 함수의 사이드 이펙트가 있는 부분과 없는 부분으로 잘 나눠서 관리
-명령(side effect O)과 조회(side effect X)를 분리하는 CQRS 방식이 있음.
 4-3) 순수 함수 형태로 사용하는 것이 더 직관적이고 에러를 방지할 수 있음


## 클린 코드 - 클래스
---
>1) 단일 책임 원칙(SRP) 지키기
: 하나의 클래스는 하나의 책임만 가지도록 하기

>2) 응집도를 높이기
: 응집도는 클래스의 변수와 메서드들이 얼마나 유기적으로 엮여있냐를 나타내는 지표. 높을 수록 클래스의 메서드들은 인스턴스 변수들을 많이 사용하며, 반대의 경우엔 적게 혹은 사용하지 않음.

>3) 변경하기 쉽게 만들기
: 일반적으로 변경하기 쉽게 설계하기 위해선 추상화를 해두고, 구체 클래스에 의존하지 않으며 추상 클래스(인터페이스)에 의존하도록 코드를 짜는 것이 중요


## 클린 코드 - 에러 핸들링
---
>1) 오류 코드보다는 예외 사용하기
: 오류 코드를 사용하면 상단에 유지인지를 판별하는 불필요한 로직이 들어가기 때문에, 예외로 명시적 에러 처리를 표현해주는 것이 좋음.

>2) 예외 클래스 잘 정의하기
: 기본만 쓰지말고 내장된 built in exception을 잘 활용하면 좋음. 상황에 맞게 Custom Exception을 사용해도 좋음. 

>3) 에러 핸들링 잘하기
: 에러 핸들링을 모을 수 있다면 한 곳으로 모음. 같은 수준의 로직을 처리할 시 한 곳으로 모아서 처리하는 편이 에러 포착에 용이

+에러가 발생하더라도 항상 실행되어야 하는 로직이 있다면 finally문을 넣어주기


## 클린 코드 - 코드 indent 줄이기(Guard Clausing, Polymorphism)
---
: if-else 조건문을 많이 사용하게 되면 코드 라인이 길어지고, indent가 많아져 가독성이 떨어지는 문제가 발생함. 이때 Guard Clausing과 Polymorhism(다형성)을 사용하면 코드를 클린하게 짤 수 있음

>1) Guard clause: 일반적으로 if-else문이 중첩(nestsed)될수록 코드는 복잡해지고 보기 지저분해지기 때문에, nested 코드를 줄이고 가독성을 높이기 위해서 코드 상단에 Fail이 되는 로직을 넣음

>2) Polymorphism(다형성): if-condition을 줄일 수 있음.


## 프로그래밍 패러다임

## 1) 절차지향 프로그래밍
: 프로시저 콜, 즉 함수 호출을 중심으로 프로그래밍을 생각하는 것.

>장점
-재사용 가능한 코드들은 별도의 함수로 분리하고 함수 간의 호출로 하고자 하는 일을 수행. 이런 프로세스는 주로 "함수"와 "조건문", "루프문" 을 활용하여 코드를 구성.
-데이터를 중앙 집중식으로 관리. 프로세스 로직과 데이터가 별도의 위치에 분리되어 있음. 프로세스 로직 부분에서는 어떤 데이터가 들어오는지 모르기 때문에 로직 내에 조건문 사용이 많은 경향이 있음
-절차지향 프로그래밍으로 작성된 코드는 일반적으로 이해하기 쉬움. TOP -> DOWN 식이며 함수라는 작은 단위로 나눠져 있기 때문. 로직이 복잡한 것이나 계속해서 기능을 확장해나가야 하는 것이 아니라면 유지보수도 용이.

>단점
-전체 로직이 매우 복잡하거나 동적으로 로직을 바꿔야 하는 등의 기능 확장이 필요할 때 유지 보수하기가 어려워짐. 또한 데이터와 함수가 분리되어 있기에 함수가 많아질수록 데이터의 변경 사항을 추적하기도 어려워짐
=>절차지향은 프로그램이 수행하는 알고리즘이 명확하고, 기능 확장 등이 자주 일어나지 않는 상황에서 사용하기에 용이

## 2) 객체지향 프로그래밍
: 객체라고 하는 단위에 책임을 명확히 하고 서로 협력하도록 프로그래밍을 하는 패러다임.

>+절차지향과는 달리 객체는 데이터와 함수(메서드)를 함께 가지고 있음. 객체 내부의 데이터는 (1)외부에 공개할 필요가 없거나 (2)사용해서는 안 되는 데이터일 경우, 모두 내부에 숨겨 외부에서 알지 못하도록 함.
-객체 지향의 특성을 *다형성이라고 하며, 어떤 객체에 필요한 객체를 때에 따라 다르게 주입해주는 것을 의존성 주입이라고 함

>장점
-객체 지향은 여러 명의 개발자들이 협력을 해야 하거나, 확장 가능하도록 코드를 설계해야 하는 경우에 적합함

>단점
-확장이 가능하고 유연한 만큼, 처음 코드를 보는 사람들은 어렵고 헷갈릴 수 있음. 또한 실행 환경에서 입력에 따라 다양한 작업 흐름이 만들어지기 때문에 디버깅하기가 상대적으로 어려움.


## 3) 함수형 프로그래밍

>-함수의 비일관성
-객체 간 의존성 문제
-객체 내 상태 제어의 어려움

=> 기존 객체지향 프로그래밍에서 가진 문제들, 함수형 프로그래밍이 대안으로 주목 받음

>함수형 프로그래밍에서는 함수가 외부상태를 갖지 않는다는 것이 중요 = 같은 입력을 넣었을 때 언제나 같은 출력을 내보임

>-> 함수의 입출력에 영향을 주는 외부 요인이 없음

>-함수형 프로그래밍 코드에서 한 번 초기화한 변수는 변하지 않음(=불변성), 불변성을 통해 안정성을 얻을 수 있음


## 함수형 프로그래밍에서 문제 해결 방법

>(1) 문제를 잘개 쪼개기
(2) 쪼개진 문제들 중 하나를 해결하는 순수 함수를 만들기
(3) 순수 함수들을 결합하여 문제들을 해결

>장점
-상태로 인한 사이드 이펙트가 없기 때문에 안정적
-> 동시성을 가지는 프로그램에 사용하기 적합하며, 특히 대용량 데이터를 병렬적으로 처리할 때 사이드 이펙트가 없도록 로직을 설계하는 것은 매우 중요. 최근 데이터 처리기술의 발전으로 함수형 프로그래밍이 부상

>단점
실제로 함수형 프로그래밍을 하기 위해선 상태를 허용하지 않기에 기존 객체 지향과 같은 기능의 코드를 구현하려면 다양한 함수들을 조합해서 사용해야 함. 또한 친숙하지 않은 설계 방식으로 인해 러닝 커브가 높음


## 프로그래밍 총정리
---
>1) 프로그래밍 패러다임이란 프로그래밍을 어떤 기준으로 바라보고 작성할 것인지에 대한 관점
>2) 절차지향 프로그래밍은 순차적인 함수 호출 중심의 관점
 ->주로 구조가 TOP-DOWN 이기에 따라서 이해하기 쉬움
 ->B, 코드를 확장하거나 자주 실행함에 따라 로직이 바뀌어야 하는 경우에 수정하기 어려움
>3) 객체 지향 프로그래밍은 객체들의 책임과 협력 중심의 관점
 ->다형성과 의존성 주입으로 코드를 확장하기 쉬우며, 실행 환경의 다양한 입력에 대응하기 좋음
 ->B, 런타임이 되기 전에 실제로 코드가 어떤 방향으로 흐르는지 알기 어려우며, 디버깅도 어려움
>4) 함수형 프로그래밍은 상태를 갖지 않는 함수들의 활용 중심의 관점
 ->상태를 가지지 않기 때문에 예측에서 벗어나는 결과(사이드 이펙트)가 없음
 ->B, 실제로 상태를 가지지 않는 함수를 작성하고 활용하는 코드를 작성하는 것은 어려움


## 객체지향
---

## 1) 클래스와 인스턴스

>클래스
ex) class User:
        pass

>인스턴스
ex) >>> user_1 ==user_2
      False 
-이때 user1과 user2는 같은 클래스로부터 만들어졌지만 서로 다른 인스턴스이며, 각자 다른 메모리 공간에 존재하고 독립된 내용을 담을 수 있음

## 2) 속성(데이터)과 메서드(행위)

>속성
: 클래스의 속성은 클래스 내에 담기는 데이터, 멤버 변수라고도 함. 클래스 속성은 크게 (1) 인스턴스 변수와 (2) 클래스 변수로 나눌 수 있음 

- (1) 인스턴스 변수
: 인스턴스별로 독립적으로 가질 수 있는 값.
- (2) 클래스 변수
: 같은 클래스의 인스턴스들이 공유. 인스턴스 변수와는 다름

> 메서드
: 클래스가 가지고 있는 함수이자 객체가 할 수 있는 행위. 메서드는 크게 (1) 공개형(public) 메서드와 (2) 비공개형(private) 메서드로 나뉨


- (1) 공개형 메서드
: 클래스가 외부에 제공해주는 메서드


- (2) 비공개형 메서드
: 클래스 내부에서만 사용하는 메서드, 외부에서 접근하지 못하거나 할 수 있더라도 하지 않는 게 관습.


-공개형 메서드의 로직의 일부를 내부적으로 재사용하고, 의미를 분리하기 위해 사용하기 위한 목적으로 사용

>+ 파이썬의 경우 자바와 다르게 접근 제어자 문법이 없음. 다만 변수나 메서드 이름 앞에 _ (underscore) 를 붙임으로써 비공개 변수, 메서드임을 명시하는 게 관습
>+ __를 두 개 붙여 조금 더 private하게 변수나 메소드를 관리할 수 있는 name mangling도 있음


## 3) 상속
: 이전에 정의한 클래스의 데이터와 메서드를 그대로 내려받는 기능. 이때 상속해주는 클래스를 부모 클래스 혹은 기반 클래스라고 하며, 상속받는 클래스를 자식 클래스 혹은 파생 클래스라고 함


## 4) 인터페이스
: 객체의 행위(메서드)만을 정의한 것으로, 구체적으로는 클래스의 메서드의 명세

- 구현체
 -> 인터페이스는 보통 그대로 인스턴스화 할 수 없기 때문에 인터페이스 객체를 상속받는 구현클래스도 구현해야 함

+ 인터페이스 사용 이유
: 구현(저수준 코드)을 의존하기 보단 인터페이스(고수준)에 의존하게 되어 결합도를 낮출 수 있으며 (-> 다형성), 구현 클래스 간의 관계를 파악하기도 쉬어지기 때문


## 객체 지향의 특성
---
1) 책임과 협력

- 1-1) 책임
: 한 객체가 특정하게 수행해야 하는 범위와 기능

- 1-2) 협력
: 객체가 서로 필요에 따라 의존하는 것

+ 책임 주도 설계
: 객체 지향에서 상황에 필요한 객체들의 책임을 중심으로 시스템을 설계해나가는 방법을 책임 주도 설계라고 함.
-하나의 책임이 곧 하나의 객체가 되고, 책임이 곧 객체의 정체성이 되는 것.
-객체들의 정체성이 명확해짐. 
-높은 응집도와 낮은 결합도를 유지하며, 시스템은 객체들의 협력으로 로직을 진행하게 됨

>2) 추상화
: 구체적인 객체(물체)들로부터 공통점을 생각하여 한 차원 높은 개념을 만들어내는(생각해내는) 것
ex) 차
차는 공통으로 가속, 감속 기능을 제공하므로 이와 같은 추상 메서드도 추가할 수 있음
-차라는 추상화된 역할의 구현체인 '모닝'과 '포르쉐' 차량은 해당 추상 클래스를 상속받아 구현할 수 있음
->사람 입장에서는 구체적인 차량이 아닌 추상적인 차라는 객체만 알면 됨

>3) 다형성
: 운전자의 입장에서 차의 형태등이 달라졌을 대의 특성을 다형성이라 함

+ 의존성 주입: 외부에서 실제로 의존하는 객체를 만들어 넘겨주는 패턴

- 객체 지향의 꽃이라 불릴 정도의 중요한 특성

- 추상 클래스 혹은 인터페이스로 객체를 상위 타입으로 추상화하고(ex 차), 그 객체의 하위 타입들(모닝, 포르쉐)은 이러한 상위 타입의 추상 클래스나 인터페이스를 구현하도록 하면 코드 설계가 전반적으로 유연해져 수정과 확장이 매우 용이해짐

>4) 캡슐화
: 객체 내부의 데이터나 메서드의 구체적인 로직을 외부에서 모르고 사용해도 문제가 없도록 하는 특성


## 객체지향 총정리
---
1) 객체 지향은 객체들의 책임과 협력으로 이루어짐
2) 추상화를 통해 객체들의 공통 개념을 뽑아내어 한 차원 더 높은 객체를 만들 수 있음
 ->객체를 사용하는 입장에서 과연 어떤 역할을 할 객체가 필요한지 생각해보고 추상화된 객체를 생각
 ->객체를 추상화한 클래스를 만든 후, 이 클래스를 상속받아 실제 구체적인 책임을 담당하는 객체를 만들 수 있음
3) 다형성으로 코드는 수정과 확장에 유연해짐
4) 캡슐화를 통해 객체 내부의 정보와 구체적인 로직을 외부에 숨길 수 있음
 ->외부에선 그저 객체가 제공하는 공개 메서드를 사용하면 됨
 ->캡슐화로 코드는 수정과 확장에도 유연해짐


## 의존성 응집도 결합도
---

>1) 의존성
- 정적 의존성: 코드 레벨에서 직접적으로 두 객체의 의존 관계를 파악할 수 있을 때(=컴파일 의존성)
- 동적 의존성: 코드 레벨에서 의존성이 드러나지는 않지만, 실제 실행 과정에서 두 객체 간 의존 관계가 있을 때

+ 정적 의존성 대상을 고수준 코드로, 동적 의존성 대상을 저수준 코드로 넣어주게 되면 더 유연한 설계가 가능해짐

>2) 응집도
: 객체의 책임에 맞게 속성과 메서드가 유기적으로 결합되어 있는 정도
-응집도를 높게 코드를 작성하면 관련성이 높은 속성과 메서드가 모여있기에 흐름을 읽기 편해짐
-불필요한 속성과 메서드를 줄일 수 있어 더 탄탄한 코드를 작성할 수 있음

>3) 결합도
: 객체간 의존하는 정도(정적 의존성)

- 한 객체가 다른 객체의 정보(속성, 메서드)를 많이 알수록 좋지 않음. 객체를 생성하거나 내부의 로직을 이해하는 데 알아야할 것이 많아지게 되며, 의존하는 객체의 속성이나 메서드가 수정되면 다른 객체 역시 영향을 받기 때문

- 객체 지향 설계에서는 객체 간의 협력이 필수적이기에 아예 의존 관계를 없애는 것은 불가능
 ->결합도를 낮게 유지할 수 있는 방향으로 코드를 작성하는 게 중요

- 결합도를 낮추기 위해선 (1) 캡슐화를 통해 내부 구현 로직을 숨기고 외부로 노출할 메서드를 추상화. 또한 (2) 팩토리 패턴, 파사드 패턴과 같은 *디자인 패턴을 활용하는 것도 방법

>+정리
개별 객체에는 책임에 따른 기능들이 충분히 모여있고(높은 응집도), 이런 객체들이 서로 협력하는 과정에서 의존하는 정도를 최소한으로 만드는 것(낮은 결합도)이 바로 객체 지향에서 말하는 좋은 설계


## Solid
---

>1) Single Responsibility, SRP(단일 책임 원칙)
: 객체는 하나의 책임만을 지녀야 한다는 법칙

- 여러 책임을 가지는 객체는 처음 코드를 짤 때는 편함
- B, 코드가 복잡해질수록 에러가 날 확률도 높아지며 직관적으로 코드를 이해하기 어려워짐
 -> 객체를 설계하기 전 책임을 확실하게  부여하는 것이 중요함

>2) Open Closed, OCP(개방 폐쇄 원칙)
: 객체의 확장에는 열려있고, 수정에는 닫혀있게 함

- 기존의 코드를 변경하지 않으면서 기능은 추가할 수 있도록 설계되어야 함.

- 요구사항이 변경되었을 때 코드의 변경되어야 할 부분과 그렇지 않아야 할 부분이 명확하게 구분되어 있어야 함
 -> 인터페이스나 추상 클래스를 통해 추상화시키고 이를 상속, 구현
 -> (다형성을 사용해)기존 코드를 변경하지 않으면서(변경에 닫혀있음) 추상 클래스를 상속받아 쉽게 코드를 추가(확장에 열려있음)

>3) Liskov Substitution, LSV(리스코브 치환 원칙)
: 부모 객체의 역할은 자식 객체도 할 수 있어야 됨

- 상위 타입에서 정한 명세를 하위 타입에서도 그대로 지킬 수 있을 때 상속을 해야함
- 상속보다는 구성

>4) Interface Segregation, ISP(인터페이스 분리 원칙)
: 클라이언트가 자신이 이용하지 않는 메서드는 의존하지 않아야 함

- 인터페이스가 하나의 책임만을 가져야 함
- 인터페이스를 책임에 맞게 잘 나눠두면 클라이언트 입장에선 필요한 역할만 구현하여 사용 가능

>5) Dependency Inversion, DIP(의존성 역전 원칙)
: 의존성을 항상 고수준으로 향하게 하여 예측할 수 없는 의존성의 변화를 줄이기

- 자주 바뀌는 구현체(저수준)를 의존하게 된다면 코드의 변경이 잦아 버그와 사이드 이펙트가 날 확률이 높아짐
 -> 코드가 덜 바뀌는 인터페이스나 추상 클래스(고수준)를 의존하면 상대적으로 안정적인 코드를 작성할 수 있음

+ 고수준은 상위 수준 + 추상화되어 있는 개념. 일반적으로 잘 변하지 않는 특성을 가지며 코드 개념에서 고수준은 인터페이스, 추상클래스 등을 예로 들 수 있음

+ 저수준은 추상화된 개념을 구체적으로 구현하는 개념. 인터페이스, 추상클래스를 구현하는 구현체(클래스)나 함수 등 실제 동작에 관여하는 코드

- 일반적으로 의존성 역전을 하면서 의존성 주입을 함께 사용.
  ->의존성 주입을 사용하게 되면 객체의 생성을 외부에 맡기게 됨. 그러면 해당 클래스는 외부 의존성에 조금 더 자유롭게 되며 테스트를 작성할 때도 용이

- 의존성 주입(DI)을 해주기 위해선 결국 이를 사용하는 클라이언트에서 의존성들을 넣어줘야함. 만약 잘못 코드를 작성하면 의존성 관계가 복잡해짐
 ->그래서 보통 의존성 주입을 별도로 관리해주는 라이브러리나 프레임워크를 사용


## 테스트 기본 이해하기
---
: 소프트웨어를 테스트하는 작업. 숨겨진 버그는 없는 지, 여러 명이 동시에 사용해도 괜찮은 지

-pip install pytest

1) 유닛 테스트
: 가장 작은 단위의 테스트

- 단일 기능을 가지는 함수, 클래스의 메서드가 잘 작동하는지 확인
- 테스트하고자 하는 코드는 다른 외부 컴포넌트(웹 서버, DB 등)에 의존성이 없어야 함
- 가장 간단하고 직관적이며, 빠르게 실행과 결과를 볼 수 있는 테스트

2) 통합 테스트
: 여러 요소를 통합한 테스트

- 데이터베이스와 연동한 코드가 잘 작동하는지, 여러 함수와 클래스가 엮인 로직이 잘 작동하는지 등을 확인
- 유닛 테스트보다는 복잡하고 느리지만, 소프트웨어는 결국 여러 코드 로직의 통합이라는 점에서 통합 테스트 역시 중요

3) E2E(End To End) 테스트
: 끝에서 끝, 즉 클라이언트 입장에서 테스트해보는 것

ex) /login 으로 POST 요청 시 로그인은 잘 되는지, /order 로 POST 요청 시 주문 결과는 잘 나오는지 등을 확인
- 보통 유저 시나리오에 따라 테스트
- 테스트 중 가장 느리지만 결국 소프트웨어를 사용하는건 유저이며, 유저 입장에서 해보는 테스트이므로 중요

> +보통 테스트는 유닛 -> 통합 -> E2E 순으로 작성, 작은 단위부터 테스트를 작성하면서 점점 통합적인 테스트를 진행하게 됨

> 테스트 개수는 가장 작은 단위 테스트인 유닛 테스트가 가장 많고, E2E 테스트가 가장 적음


## 테스트 코드가 필요한 이유
---

1) 코드가 동작하기 위해 필요한 것들과 입/출력을 드러냄

- 테스트는 테스트하고자 하는 코드의 클라이언트 중심으로 작성. 즉 테스트하고자 하는 코드를 사용하려면 어떤 의존성이 필요한지, 어떤 입력을 주면 어떤 출력을 뱉는 지를 테스트 코드를 보면 알 수 있음
 -> 테스트 코드는 프로젝트 코드에 대한 가장 정확한 문서가 됨. 테스트 코드만 보면 코드를 돌리는데 필요한 것들을 알 수 있기 때문

2) 리팩토링과 지속적인 개발을 위해 필수적

- 테스트 코드 없이 개발을 계속해서 해나가면 추가로 개발한 코드가 기존 코드의 어떤 사이드 이펙트를 불러일으키는지 확인하기 어려움.
 -> 테스트 코드를 만들어두면 추가로 코드를 개발할 때마다 기존 테스트 코드를 모두 실행함으로써 기존 코드의 작동 여부에 사이드 이펙트가 있는 지 빠르게 확인 가능
 => 테스트 코드는 일종의 안전망


## 테스트 더블
---
: 의존성 객체들을 대체함으로써 테스트를 좀 더 원활하게 진행하기 위한 객체

- 종류

1) dummy
: 실제 내부 동작은 구현하지 않은 채, 객체의 인터페이스만 구현한 테스트 더블 객체. 메서드가 동작하지 않아도 테스트에 문제가 없을 때 사용

2) stub
: dummy 테스트 더블 객체에서 테스트에 필요한 최소한의 구현만 해둔 테스트 더블 객체. 테스트에서 호출될 요청에 대해 미리 준비해둔 결과만을 반환

3) spy
: stub에서 테스트에 필요한 정보를 기록해두는 테스트 더블 객체. 보통 stub의 역할을 포함하며, 실제로 내부가 잘 동작했는지 등을 별도의 인스턴스 변수로 기록해둠

4) fake
: 동작의 구현은 갖추고 있지만, 테스트에서만 사용할 수 있는 테스트 더블 객체. 대체할 객체가 복잡한 내부 로직이나 외부 의존성이 있을 때 사용

5) mock
: 테스트에 필요한 인터페이스와 반환 값을 제공해주는 객체. 해당 메서드가 제대로 호출됐는지를 확인하는 행위 검증의 기능을 가지며, 다른 테스트 더블과 다르게 보통은 객체를 직접 정의하지 않고 보통 Mock 객체로 반환 값을 미리 지정해둠.
 -> 대부분의 테스트 프레임워크는 Mocking을 정밀하게 할 수 있도록 지원해줌


## TDD(Test Driven Development)
---
: 테스트가 개발을 이끌어가는 방법론. 테스트가 개발보다 선행됨

> 개발해야 하는 사항을 미리 정의 -> 각 기능의 입출력을 미리 정한 후 기능을 구현하는 프로세스는 아주 일반적인 개발 과정
> TDD 방식으로 개발하게 된다면, 테스트 코드를 먼저 작성함으로써 개발사항과 각 기능의 입/출력 요구사항을 코드로 문서화한 후 기능을 개발하게 됨

> 장점
-개발하고자 하는 대상에서 기대하는 것을 테스트 코드로 미리 명확하게 정의할 수 있음
 ->소프트웨어를 개발할 때 중요한 것은 이 소프트웨어가 "어떻게"가 돌아가느냐가 아니라 "무엇을" 제공해줄 것이냐
 ->테스트 코드로 먼저 작성하면 입/출력과 발생하는 예외를 무엇으로 정의해야 할지 먼저 명확하게 정의할 수 있음
 ->덕분에 좀 더 사용하는 쪽의 코드나 사람 입장에서 사용하기 좋은 코드를 작성할 수 있게 됨

>-테스트를 훨씬 꼼꼼히 작성하게 됨
 ->구현을 먼저하고 테스트를 작성하면 테스트 작성에 느슨해지고 자칫 예외나 몇몇 시나리오에 대한 테스트를 놓칠 수 있음
 ->TDD로 진행하게 되면 테스트를 먼저 작성하기 때문에 테스트 코드를 누락시킬 빈도가 낮아짐

>-테스트 코드가 깔끔한 코드 사용 문서가 됨
 ->TDD에서 테스트 코드는 테스트할 대상의 구현을 모른 채 작성되기 때문에 철저히 사용자 중심적으로 작성됨
  ->따라서 테스트 코드는 코드를 사용하기 위해 필요한 최소한의 내용만 담게 됨

> 단점
-테스트가 가능하도록 코드를 설계하는 것은 어려움
 ->TDD를 진행하게 되면 모든 코드들을 테스트 가능하도록 설계해야 함
 ->추상화, 의존성 주입 등을 잘 활용해야 함
 ->테스트 환경을 제대로 구축하는 (Docker compose, DB 데이터 초기화 등) 작업이 번거로움

- 익숙하지 않은 채 TDD를 진행하면 개발 프로세스가 느려질 수 있음
 -> 구현 로직보다 테스트 코드를 작성하고 고민히는데 훨씬 시간이 많이 들 수 있음


## TDD 정리
---
> (1) 테스트가 구현을 선행하는 개발 프로세스
(2) 보통 레드-그린-리팩토링 순서로 개발을 진행하게 됨
(3) 꼼꼼한 테스트를 통해 코드 품질과 테스트 코드의 문서화 품질이 올라감
(4) 테스트 가능한 코드와 테스트 환경을 갖추는 일은 어려움


## 소프트웨어 아키텍처
---
: 소프트웨어의 전체적인 구조를 잡아주는 설계도
>유명한 아키텍처들은 자주 사용되며 패턴화됨
ex) 레이어드 아키텍처, MVC 패턴


## 아키텍처 없는 프로젝트의 문제점
---
>-본인이 작성한 코드나 모듈을 어느 곳에 위치할 지 고민하거나 결정하는 데 시간이 낭비됨
-모듈 위치나 이름이 일관성 없게 됨
-폴더, 파일 간의 의존 관계가 복잡해지면서 컴포넌트를 나누기가 힘들어짐
-전체적인 흐름과 설계를 이해하는 데 시간이 오래 걸림


## 아키텍처의 장점
---

>-시스템에 규칙이 생김
 ->개발자들이 일관적이고 견고한 코드를 만들 수 있음
 ->개발자들이 모듈 분리와 추상화에 대한 고민을 덜기 때문에 코드 생산성이 올라감
 ->아키텍처를 파악하면 누군가 작성한 코드를 파악하거나 새로 코드를 작성하는데 빠르게 감을 잡을 수 있음

>-소프트웨어의 구성을 한 눈에 파악하기 좋음
 ->이런 아키텍처들을 채택함으로써 개발자 간의 커뮤니케이션 비용을 줄일 수 있음
 ->소프트웨어의 테스트를 쉽게 만들 수 있도록 도움
 ->코드를 언제든지 바꿔도 동작에 문제가 없도록 보장받을 수 있음


## 트레이드오프 - 아키텍처 도입 시의 어려움
---

>-초반에 아키텍처를 고민하고 결정하는 시간이 필요
-코드를 작성하거나 읽어야 할 때 알아야 될 규칙이 늘어남
-팀원 전체가 프로젝트의 아키텍처 패턴에 익숙해야 함
-전반적으로 작성해야 할 코드의 양이 늘어남

+아키텍처를 처음에 쉽게 이해하기 위해서는 의존성 관계에 집중해야한다


## 레이어드 아키텍처
---
: 여러 레이어를 분리하여 레이어마다 해야 할 역할을 정의해놓은 구조


## 대표적인 레이어드 아키텍처 '4계층'
---

1) 프레젠테이션 레이어
인터페이스와 애플리케이션이 연결되는 곳
웹 통신 프레임워크, CLI 등 인터페이스, 입출력의 변환 등 외부와의 통신을 담당합니다.

2) 애플리케이션 레이어
: 소프트웨어가 제공하는 주요 기능(비즈니스 로직)을 구현하는 코드가 모이는 곳
-로직을 오케스트레이션하고, 트랜잭션의 시작과 끝을 담당

3) 도메인 레이어
: 도메인과 관련된 객체들이 모이는 곳
-도메인 모델(엔티티, 값 객체), 도메인 서비스 등 도메인 문제를 코드로 풀어내는 일을 담당

4) 인프라스트럭처 레이어
: 다른 레이어을 지탱하는 기술적 기반을 담은 객체들이 모이는 곳
-DB와의 연결, ORM 객체, 메시지 큐 등 애플리케이션 외적인 인프라들과의 어댑터 역할을 담당


## 레이어드 아키텍처 - 의존성의 방향
---

: 프레젠테이션 레이어 -> 애플리케이션 레이어 -> 도메인 레이어 -> 인프라스트럭처 레이어
+3레이어의 경우엔 도메인이 빠짐

> 장점
>-레이어마다 정해진 역할이 있음. SRP(단일 책임 원칙)와 비슷하게 레이어 간의 책임을 두고 분리해서 유지보수 및 코드 관리가 용이
-레이어 간의 의존 흐름이 바깥쪽(프레젠테이션 레이어)에서 안쪽(인프라스트럭쳐 레이어)으로 일정함. 새로운 기능을 개발할 때 통일된 흐름에 맞게 빠르게 개발이 가능
-코드를 처음 보는 사람은 의존성의 흐름에 따라 자연스럽게 전체적인 구조를 쉽게 파악할 수 있음

> 단점
: 소프트웨어가 최종적으로 인프라스트럭처(ex. DB)에 의존성을 갖도록 한다는 것
-DB가 소프트웨어의 설계 핵심에 영향을 미치기 때문에, 소프트웨어의 모든 구조가 DB 중심의 설계가 됨. 이 경우엔 애플리케이션 설계에 앞서 데이터베이스를 먼저 선택하고, 데이터베이스 설계(데이터 모델링)부터 하게 됨. 또한 객체 지향에서 추구하는 "액션"이 먼저가 되는 것이 아니라 "상태" 중심적으로 설계를 하기 때문에 점점 객체 지향에서 벗어나는 코드들이 생기게 됨


## 헥사고날 아키텍처
---
: 애플리케이션을 중심으로 보며 DB, 웹 프레임워크 등은 모두 애플리케이션이 사용하는 부품(언제든 갈아끼울 수 있는)으로 보는 아키텍처
+클린 아키텍처도 이에 해당함

> -가운데 애플리케이션을 중심으로 애플리케이션 외의 모듈은 애플리케이션에서 제공하는 포트 모양에 맞다면 언제든 바꿀 수 있도록 함
 -어댑터가 포트 모양만 맞으면 동작하는 것 같다고 하여 포트 앤 어댑터(Ports-and-Adapters)라고 부르기도 함. 즉 포트만 맞다면 어떤 어댑터든 포트에 끼울 수 있음

- 구조
1) 도메인: 애플리케이션의 핵심

2) 애플리케이션:
-도메인을 이용한 애플리케이션의 비즈니스 로직을 제공
-관용적으로 Service라고 표현함
-애플리케이션은 포트를 지님
 ->포트는 프로그래밍 문법에서 인터페이스로 구현할 수 있음

3) 어댑터
-애플리케이션 내에 있는 포트에 끼울 수 있는 구현체
-web이나 cli 등은 인바운드 포트에 끼울 수 있는 인바운드 어댑터에서 이용
-db 등은 아웃바운드 포트에 끼울 수 있는 아웃바운드 어댑터를 통해 이용
-어댑터는 보통 포트를 나타내는 인터페이스를 상속받아 구현


## 헥사고날 아키텍처 - 의존성의 방향
---

: 어댑터 -> 애플리케이션 -> 도메인
위의 의존성 흐름을 역행하면 안 됨. ex) 비즈니스 로직 -> 어댑터, 도메인 -> 어댑터로 흐르는 의존성이 없어야 함

+포트 앤 어댑터의 의존성 원칙은 저수준이 아닌 고수준에 의존하라는 의존성 역전 원칙과도 동일 선상에 있음.
보통 컴파일 의존성(코드 의존성)에서는 고수준을 의존하게 한 후, 런타임에서 의존성을 주입(의존성 주입 프레임워크를 많이 활용함)


## 클린 아키텍처(by 로버트 C. 마틴)
---

- 핵심내용

1) 세부 사항(DB, 프레임워크)가 정책(업무 규칙)에 영향을 주면 안 됨
2) 계층별로 관심사를 명확하게 분리하여 변경이 필요할 때 영향을 주는 부분을 최소화함
3) 내부 계층이 외부 계층을 의존하지 않아야 함(의존성 흐름은 바깥에서 안으로)

+ 아키텍처들은 관심사 단위로 레이어를 나눔

1) 엔티티
-핵심 업무 규칙을 캡슐화
-메서드를 가지는 객체이거나 일련의 데이터 구조와 함수의 집합일 수 있음
-가장 변하지 않고, 외부로부터 영향받지 않는 영역

2) 유스 케이스
-애플리케이션에 특화된 업무 규칙을 포함함
-시스템의 모든 유스 케이스를 캡슐화하고 구현
-엔티티로 들어오고 나가는 데이터 흐름을 조정하고 조작

3) 인터페이스 어댑터
-일련의 어댑터들로 구성
-어댑터는 데이터를 (유스 케이스와 엔티티에 가장 편리한 형식) <-> (데이터베이스나 웹 같은 외부 에이전시에 가장 편리한 형식)으로 변환함
-컨트롤러(Controller), 프레젠터(Presenter), 게이트웨이(Gateway) 등이 여기에 속함

4) 프레임워크와 드라이버
-시스템의 핵심 업무와는 관련 없는 세부 사항이므로 언제든 갈아 끼울 수 있음
-프레임워크나, 데이터베이스, 웹서버 등이 여기에 해당

+ 레이어는 상황에 따라 4가지 이상일 수 있음
: 핵심은 안쪽 영역으로 갈수록 추상화와 정책의 수준이 높아지고, 반대로 바깥쪽 영역으로 갈수록 구체적인 세부사항으로 구성된다는 것. 안쪽 영역으로 갈수록 고수준이라고 하며, 바깥쪽으로 갈수록 저수준


## 의존 방향 규칙
---
: 의존성 방향은 항상 저수준에서 고수준으로 흘러야 함. 바깥쪽 원에서 안쪽 원으로 의존성이 있어야 하며, 반대로 고수준에서 저수준으로 의존성이 흐르면 안 됨. 안쪽 원은 바깥쪽 원의 어떤 것도 알지 못해야 함.

- B, 실제로 애플리케이션이 동작할 때의 제어 흐름은 이런 의존 흐름과는 반대.

> -> 클린 아키텍처에서는 이런 의존성 방향을 제어하기 위해 의존성 역전 원칙을 지킴. 즉 추상화된 인터페이스를 고수준 레이어에 두고 이 인터페이스를 사용함. 그리고 저수준에는 이 인터페이스를 상속받는 객체를 구현함. 이렇게 되면 고수준 컴포넌트가 저수준 컴포넌트에 의존하게 되지 않고, 반대로 저수준 컴포넌트가 고수준 컴포넌트에 의존하게 됨


## 모놀리스 아키텍처
---
: 하나의 소프트웨어를 구성하는 모든 모듈과 코드를 한 프로젝트에서 관리하는 것

> 장점
(1) 한 프로젝트 내에 모든 모듈과 코드가 있으므로 개발이 간단하고 리뷰가 용이
(2) 소프트웨어 구조가 비교적 단순해서 애플리케이션을 구성하는 큰 그림을 보는데 편리
(3) 애플리케이션 기동에 main.py 만 실행시키면 되므로 배포하기 쉬움
(4) 디버깅 등의 장애 대응이 비교적 쉬움

> 단점
(1) 애플리케이션 코드가 점점 많아지고 서비스가 확장되면 전체 구조나 코드 흐름을 쉽게 이해하기 어려움
(2) 한 프로젝트 내에 있는 코드이므로 모든 코드가 결합되어 있음 ->코드 변경과 확장이 어려워짐
(3) 개발 속도가 느려짐. 코드를 작성하려면 전체 코드를 다 이해해야 하기도 함
(4) 한 번에 테스트해야 할 양이 점점 늘어나 테스트 속도가 매우 느려짐(&빌드)
(5) 모든 코드에 영향이 가기 때문에 최신 기술 스택이 나와도 쉽게 도입하기 어려움
+보통 기능 개발과 속도가 중요한 사업 초기에는 애플리케이션을 모놀리스 아키텍처로 구성함


## 마이크로서비스 아키텍처
---
: 하나의 소프트웨어를 구성하는 컴포넌트들을 독립적인 프로젝트들로 분리하여 관리하는 것

- 각각의 컴포넌트들을 마이크로 서비스라고 부르며, 개발과 배포도 이렇게 분리된 마이크로서비스 단위로 진행함. 즉 하나의 소프트웨어가 정상적으로 동작하기 위해서는 이를 구성하는 각각의 마이크로서비스가 모두 정상 작동해야 하기 때문에 이러한 방식은 보통 소프트웨어가 커지고 복잡해질 때 필요함

> 장점
(1) 각 마이크로서비스가 모놀리스보다 작은 규모이기 때문에 마이크로 서비스별로 보면 코드 구조나 흐름을 이해하기 쉬움
(2) 전체적으로 분리가 되어있기 때문에 마이크로서비스간 결합이 강하지 않으므로 각 서비스별로 수정이나 확장을 시도하기 편함
  ->개발 속도가 빨라짐(특히 각 마이크로서비스를 담당하는 전담 팀들이 있을 때)
(3) 한 번에 테스트할 양도 마이크로서비스 단위로 나뉩니다. 테스트와 빌드, 배포 속도가 빨라집니다.
(4) 마이크로서비스별로 사용할 컴퓨팅 리소스(cpu, memory, etc)를 다르게 줄 수 있습니다. 또한 서버 개수도 다르게 둘 수 있습니다. 이는 요청 증가에 따른 서버 확장에 용이합니다.
(5) 기술 스택도 각 마이크로서비스 별로 다르게 가져갈 수 있습니다. 예를 들어 Users 서버는 Java, Products 는 파이썬, Payment 는 JS로 개발할 수 있습니다. 이처럼 각 마이크로서비스는 독립적인 환경에서 개발되기 때문에 기술 도입이 유연해집니다.

> 단점
(1) 각 서비스들이 분산되어 있기에 여러 연관된 서비스를 통합하여 테스트할 때 난이도가 높아짐
(2) 처음에 어떤 기준으로 마이크로서비스를 나눌지 결정하는 것이 어려움. 잘못 나눌 시 마이크로서비스간 결합도는 높아지고, 관리 비용은 늘어날 수 있음
(3) 각 담당 팀에서 마이크로서비스만 집중해서 개발하다보면 서비스의 전체 큰 그림을 파악하기 어려울 때가 있음. 이런 큰 그림과 흐름을 파악하기 위해 커뮤니케이션 비용이 들어감
(4) 여러 서비스에 걸친 분산 트랜잭션 처리 등 분산 시스템 환경에서 고민할 문제들이 다수


## 총정리
---
1) 모놀리스 아키텍처는 하나의 소프트웨어를 하나의 프로젝트로 개발하는 아키텍처
- 한 프로젝트 내에 모든 모듈과 코드가 담겨있음
- 모든 개발자가 이 프로젝트에서 개발하고 협업함
- 규모가 작은 프로젝트의 경우 코드 파악도 용이하고, 빌드와 배포도 빠름
- 서비스 초기에 프로젝트 규모가 작을 때 주로 사용

2) 마이크로서비스 아키텍처는 하나의 소프트웨어를 여러 독립된 프로젝트로 나누어 개발하는 아키텍처
- 하나의 서비스는 여러 마이크로 서비스로 분리됨
- 각 마이크로서비스 단위로 개발하고 배포함. 보통 이 마이크로서비스 단위로 개발팀이 조직됨
- 규모가 큰 프로젝트의 경우 마이크로 서비스 단위로 코드를 파악하기 용이하고, 빌드와 배포도 빠름
- 서비스가 성장하고 프로젝트 규모가 커질 때 모놀리식에서 마이크로서비스로 전환하기도 함


## 프로세스
---
: 운영체제에 의해 연속적으로 실행되고 있는 프로그램

- 유저가 프로그램을 실행했다면 프로세스는 메모리 위에 올라가 있게 되며 운영체제에 의해 CPU, 메모리 자원을 할당받게 됨

- 프로세스: 독립된 메모리 영역. Code, Data, Stack, Heap을 할당받음

- Code: 개발자가 작성한 코드

- Data: 전역변수, 정적변수, 배열, 구조체 등 프로그램이 실행되면서 생기는 정적인 데이터들이 저장됨

> Stack은 함수 호출과 관련된 정보(실행정보, 지역변수, 파라미터 등)이 저장됩니다. 일반적으로 컴파일 타임에 Stack의 크기가 결정됨

+ Stack Overflow
: 프로세스에 할당된 Stack 메모리가 초과했을 때 생기는 문제. 함수에 너무 큰 지역변수를 선언하거나 재귀적 무한정으로 함수를 호출하게 될 때 발생

+Heap: 런타임에 동적으로 메모리를 처리해야 하는 상황에서 사용되는 공간
- Array를 사용하거나 외부 파일을 읽을 때 등을 예시로 들 수 있음
- 사용자에 의해 메모리 공간이 동적으로 할당되고 해제될 수 있음


## 스레드
---
: 특정한 시점에 프로그램의 작업을 수행하는 역할을 함. 일반적으로 프로세스 안에서 실제 코드를 실행하는 단위
> -> CPU 이용의 기본 단위입니다. 한 개의 스레드 작업은 1개의 CPU 코어에 할당됨
-> 스레드가 실행되기 위해선 자원(함수 실행 정보, 지역 변수 등)을 저장할 메모리가 필요하며, 이는 프로세스가 할당받은 메모리를 사용함

> -스레드는 프로세스 내에 존재하기에 프로세스의 자원을 공유하게 됩니다. 각자의 스레드는 Stack을 별도로 가지고 있게 되며 나머지 자원(Code, Data, Heap)을 공유함
 ->여러 스레드가 실행된다면 프로세스의 자원을 공유하기에 빠르게 자원을 가져다 쓸 수 있음.  반면 프로세스가 다른 프로세스의 자원을 사용하기 위해서는 IPC(Inter-Process Communication)라는 방식을 사용해야 함

>-프로그램을 실행하면 일반적으로 1개의 프로세스와 1개의 메인 스레드를 가지게 됨. 그러나 프로그램이 해야 할 태스크들이 많아지면 자연스럽게 여러 개의 스레드를 동시에 실행할 수 있으며, 혹은 여러 개의 프로세스를 동시에 운영할 수도 있음


## 동시성
---
: 사용자가 모든 프로세스의 명령이 동시에 처리된다고 느끼되는 현상
- 제한된 자원에서 여러 작업을 한 번에 실행시키려는 논리적인 개념


## CPU Bound와 I/O Bound
---
: 컴퓨터가 수행하는 하나의 작업은 CPU와 I/O 작업로 이루어짐.  CPU Bounded Task와 I/O Bounded Task

- CPU Bounded Task는 작업을 실행하는데 I/O보다는 CPU를 더 많이 쓰는 작업을 뜻함. 예를 들면 머신 러닝과 같이 연산이 복잡한 로직이 여기에 해당. I/O 작업이 아예 없는 것은 아니지만 대체로 CPU 사용량이 더 압도적

- I/O Bounded Task는 작업을 실행하는데 CPU보다는 I/O가 더 많은 작업을 뜻함. 예를 들면 크롤링 로직, DB와 연결하여 데이터를 주고받는 로직 등이 여기에 해당. 일반적으로 웹, WAS 서버는 I/O Bounded한 경우가 다수


## 병렬성
---
: 여러 개의 작업을 동시에 진행되는 현상

- 동시성은 실제로는 하나의 명령을 빠르게 수행하지만 처리속도가 매우 빨라 여러 작업이 동시에 진행되는 것처럼 느껴지게 해주었다면, 병렬성은 실제로 여러 개의 명령어를 동시에 실행하는 것. 운영체제가 여러 CPU를 골고루 쓰도록 매니징해줌


## 멀티 스레딩
---
: 하나의 프로세스에서 여러 개의 스레드를 사용하는 것
+ 하나의 프로세스에서 하나의 스레드만 사용하는 것은 싱글 스레딩

- 멀티 스레딩은 동시성과 병렬성을 구현하는 방법 중 하나
- 컴퓨터가 하나의 CPU 코어만 가진 경우 동시성이 되고, 여러 개의 코어를 가진 경우 동시성과 병렬성이 둘 다 구현됨
- 독립적인 I/O Bounded 작업이 많은 경우에 많이 사용됨
 ->ex) 여러 사이트를 크롤링해야 하는 경우


## 멀티 프로세싱
---
: 프로그램 실행에 2개 이상의 프로세스를 사용하는 것


## 총 정리
---
1) 멀티 스레딩은 하나의 프로세스에서 여러 개의 스레드를 사용하는 것
- 스레드간 하나의 프로세스의 메모리 공간을 공유
- 멀티 프로세싱보다 메모리 공간을 적게 쓰고, 컨텍스트 스위칭도 빠름
- 하지만 동시성 문제와 안정성에 대한 단점이 존재

2) 멀티 프로세싱은 하나의 프로세스에서 여러 프로세스를 사용하는 것
- 각 프로세스는 독립된 메모리 공간을 사용
- 동시성과 안정성에 대한 장점을 가지지만 멀티 스레딩보다 메모리 공간을 많이 쓰고, 컨텍스트 스위칭도 느림

3) 멀티 스레딩과 멀티 프로세싱은 동시성과 병렬성의 구현 방법
4) 병렬성을 가지면서 동시성을 가질 수도 있음
- 멀티 프로세싱을 하도록 구현함과 동시에 각 프로세스에서 멀티 스레딩을 하도록 구현하면 병렬성과 동시성 모두 가져감


## 동기와 비동기
---
: 두 작업의 작동 방식에 대한 내용

1) 동기
: 대부분의 코드, 직관적이고 이해가 쉬우며 설계또한 단순

2) 비동기
: 동기보다 비직관적이고 이해하기 어려움. 설계 또한 복잡하나 요청 결과를 받을 때까지 기다리지 않고 다른 작업을 수행할 수 있어 효율적
+응답에 대해서 처리를 하는 코드를 따로 작성해줘야 함. 이때 콜백(Callback) 방식을 많이 활용


## 블락과 논블락
---
: 작업의 상태에 대한 내용

1) 블락
: 프로세스의 제어권이 다른 함수에 넘어간 상태

2) 논블락
: 블락 상태를 가지지 않는 상태

+ 동기는 블락과, 비동기는 논블락과 비슷한 개념처럼 보여짐

- 동기/비동기는 한 작업에서 다른 작업의 작업 완료 여부에 관심이 있느냐에 있음. 즉 관심이 있다면 동기 작업이고, 관심이 없다면 비동기 작업

- 블락/논블락은 한 함수에서 호출한 다른 함수가 바로 리턴을 하여, 현재 진행 중인 함수의 프로세스 제어권을 가져가느냐 아니냐에 있음. 호출한 함수가 바로 리턴하지 않아 프로세스 제어권을 뻇기게 되면 블락상태에 있게 되는 것. 반면 바로 리턴하게 된다면 논블락 상태에 있게 됨


## 가상화 기술과 도커
---

1) 가상화 기술
: 하드웨어 리소스를 추상화하여 소프트웨어화 하는 기술

+ 가상화 기술의 등장 이전

- 하나의 서비스를 제공하기 위해서는 하나의 컴퓨터 전체에 서버 프로그램을 띄워서 사용해야만 했음. 사용량이 적은 서비스더라도 컴퓨터의 CPU, Memory 등의 리소스를 전부 사용할 수 밖에 없었음

- OS나 하드웨어의 특징에 따라 소프트웨어의 동작에 영향을 끼침. 예를 들어 리눅스 컴퓨터에 서버를 운영하는 회사에서 개발자들이 Window 컴퓨터와 Mac 컴퓨터를 사용한다면 핑계를 댈 수 있음

> => 가상화 기술이 등장하며 해결

- 1-1) VM(Vertual Machine)
: 하드웨어를 가상화하는 기술 중 하나. 컴퓨터에 기본적으로 설치한 OS(Host OS) 위에 Hypervisor라는 소프트웨어를 통해 여러 OS(Guest OS)를 띄우고 컴퓨팅 리소스를 제어할 수 있음. 또한 만든 각각의 환경에서 애플리케이션을 독립적으로 실행할 수 있음

> 단점
(1) 용량을 많이 차지
(2) 실행환경의 부가적인 설정들을 완전히 구현하기 어려움

- 1-2) 컨테이너
: VM과 마찬가지로 이미지로 실행환경을 가상화하고 실행시킬 수 있는 도구

- 1-3) 도커
: 컨테이너를 실행하기 위한 컨테이너 엔진


## 총정리
---

1) 가상화 기술의 큰 축은 VM과 컨테이너 기술
-VM은 이미지마다 전용 운영체제가 있기에 안정적인 프로세스 격리가 가능하지만, 이미지 용량이 크고 속도가 느린 편
-컨테이너 기술은 VM과 다르게 Guest OS를 가지지 않도록 기술적으로 구현되었기에 상대적으로 가볍고 빠름

2) 컨테이너 기술을 쉽게 실행하고 관리할 수 있도록 돕는 오픈소스 플랫폼으로 도커가 있음
-Dockerfile 내에 실행하기 위한 모든 설정이 기록되어 있기 때문에 Docker 문법을 아는 사람이라면 쉽게 실행환경을 이해할 수 있고 재현할 수 있음
-Dockerfile 에 작성된 설정 말고는 별다른 의존성이 없기 때문에 도커가 설치된 어느 컴퓨터에서든 도커 이미지를 실행시키면 동일한 실행환경에서 소프트웨어를 실행시킬 수 있음


## 배포와 CI/CD
---

1) 배포 방법의 변화

- 1-1) 직접 소스코드 설치 & 실행
1-2) FTP나 원격저장소로 설치 & 실행
 ->코드를 실행하는 환경과 배포의 독립성 이 중요한 이슈로 떠오름
1-3) VM 위에서 배포하기
1-4) 컨테이너 기반(Docker)으로 배포하기
 ->VM보다 가벼우면서도 독립적인 실행환경을 갖출 수 있음. 또한 Dockerfile 내에 실행하기 위한 모든 설정이 기록되어 있기 때문에, Docker 문법을 아는 사람이라면 쉽게 실행환경을 이해할 수 있고 재현할 수 있음

2) CI/CD
: 작업한 코드를 원격 저장소(GitHub)에 올리게 되면 즉시 배포가 됨
ex) Jenkins, CircleCI, Travis, GitHub Action, BuddyWorks


+ HTTP 프로토콜의 특징으로 비연결성(Connectionless)와 무상태성(Stateless)이 있음. 비연결성은 한 번의 HTTP 통신으로 요청과 응답이 오간 이후에 통신을 끊는다는 것이며, 이로 인해 통신과 관련된 상태는 남지 않음

> => 이렇게 상태 값을 가지지 않는 HTTP 통신 환경의 문제를 세션과 쿠키를 활용해서 해결할 수 있음

## 쿠키와 세션
---

1) 쿠키
: 웹 서버와 통신 과정에서 특정 정보를 저장하기 위한 Key - Value 형태의 유효기간을 가진 데이터

- 과정
1-1) 웹 서버에서는 클라이언트(웹 브라우저)에게 특정 데이터를 남기고 싶을 때 응답 HTTP 헤더에 Set-Cookie: 데이터를 기록
1-2) 브라우저는 자동으로 HTTP 헤더의 쿠키 정보를 읽고 웹 서버의 도메인에 매칭해서 저장
1-3) 나중에 웹 서버에 HTTP 요청을 날리게 되면 자동으로 쿠키를 헤더에 담아서 전송

- 쿠키는 도메인 별로 다양하게 둘 수 있으며 서버 세션 관리, 트래킹, 사용자 개인화, 인증/인가 등에 쓰임.

2) 세션
: 클라이언트와 서버 간의 네트워크 연결에 대한 정보를 담고 있는 객체

- 서버 쪽에서 관리하는 객체이며 클라이언트와의 연결에 대한 정보를 담음. 세션 저장을 위해 별도의 세션 스토리지를 구현함

+ 세션과 쿠키의 차이
: 인증에 대한 정보를 어디에 저장하는 지

- 쿠키는 정보를 클라이언트 쪽에 저장함. 인증 절차에 대한 모든 정보가 클라이언트에 저장한 쿠키에 있으며, 세션은 이 정보를 서버 쪽에 저장함. 

- 세션과 쿠키는 서로 대립하는 관계가 아님. 쿠키는 브라우저에 특정 데이터를 저장하는 방식이지만, 세션은 클라이언트/서버 구조에서 연결 정보(객체)를 저장하는 방식


## 사용자 인증
---

1) 인증 방식

- 1-1) 계정 정보를 클라이언트에서 저장
: 매번 요청에 계정 정보를 담지 않아도 됨. 그러나 브라우저의 쿠키에 유저의 인증 정보가 그대로 남아있기 때문에 보안에 취약함. 또한 서버에서는 요청에 포함된 쿠키를 계속해서 데이터베이스와 통신해야 하기 때문에 자원 낭비 및 성능 저하로 연결될 수 있음
+ 계정 정보와 인증이 필요없는 경우엔 충분

- 1-2) 세션 기반 인증
-계정 정보를 브라우저의 쿠키에 그대로 노출하지 않음
-세션의 유효기간을 설정할 수 있기에 보안과 다양한 기능(동시 접속 차단 등)을 구현할 수 있으며 데이터베이스의 부하를 줄일 수 있음
-인증에 필요한 데이터들을 서버 혹은 별도의 세션 서버에서 관리하기 때문에 서버에 부하가 생김
 ->대규모 서비스 운영을 위해선 세션 저장소를 체계적으로 관리하는 일도 중요

- 1-3) 토큰 기반 인증
: 별도의 저장소를 사용하지 않고 토큰이라고 하는 하나의 문자열에 인증에 필요한 데이터를 모두 담는 방법
ex) JWT
-세션처럼 별도의 세션 저장소가 필요하지 않기에 상대적으로 구현이 간편함
-토큰에 많은 데이터를 저장할수록 토큰이 커지면서 네트워크 통신 비용이 비싸짐
-한 번 발급된 토큰에 대해서는 중간에 폐기할 수 없다는 단점도 존재

2) 인가
: 인증을 마친 사용자가 요청에 대해 유효한 권한을 가지고 있는지 확인하는 작업

- 어떤 자원에 대해 접근을 사용자의 권한(Role)에 따라 다르게 설정해주는 것이 중요


## OSI 7계층과 TCP/IP 4계층 모델
---

1) OSI 7계층 모델
: 네트워크 통신의 과정을 7단계의 계층으로 나눈 설계

 - 계층을 나눌 시의 장점
-전체적으로 필요한 일을 여러 계층으로 나누면 계층별 해야 할 일이 명확해짐
-전체적인 설계 모델이 있으면 설명이나 이해가 쉬워짐
-각 층을 나누면 층별로 필요한 데이터들을 표준화할 수 있음

 - OSI 7계층 단계
1-1) 응용 계층(브라우저)에서 데이터(URL)를 입력
1-2) 데이터는 전송 전에 내부적으로 표현 계층, 세션 계층, 전송 계층, 네트워크 계층, 데이터 링크 계층 을 차례대로 지나며 네트워크 통신에 필요한 데이터를 기존 데이터에 추가
 -> 각 계층은 순서를 가지며, 응용 계층 -> 물리 계층 순으로 전달
  -> 이전 계층으로부터 데이터를 전달받으며 자신의 계층에서 필요한 데이터들을 기존 데이터에 추가로 붙임
1-3) 물리 계층에서는 계층을 지나며 만든 데이터를 실제로 네트워크에 전송
1-4) 서버는 이 데이터를 수신받아 다시 물리 계층 -> 응용 계층 순으로 전달
  -> 각 계층은 마찬가지로 이전 데이터로부터 데이터를 전달받으며, 필요한 데이터만 분리하여 해석함
1-5) 최종적으로 응용 계층에서는 요청을 웹서버에 전달한 뒤, 웹서버는 송신자에게 필요한 응답(메인 페이지)를 다시 데이터로 만듦

2) 프로토콜
: 통신을 위한 형태 또는 규약
 ex) HTTP, TCP, UDP

> 각 계층이 하는 일
-계층 7, 응용 계층 (Application Layer)
: 웹 서비스의 UI 부분, 사용자의 입출력(I/O)을 담당
-프론트 엔드, 백엔드 서버가 이 레이어 위에서 동작

>계층 6, 표현 계층 (Presentation Layer)
: 응용 계층과 네트워크 계층을 위해 계층 간 데이터를 적절히 표현하는 부분을 담당
-이미지를 압축하거나 데이터를 암호화 하는 등의 기능이 이 레이어 위에서 동작

>계층 5, 세션 계층 (Session Layer)
: 통신 세션을 구성

>계층 4, 전송 계층 (Transport Layer)
: 컴퓨터로 들어온 네트워크 데이터를 어느 포트로 보낼지 담당
-네트워크가 끊기거나 데이터가 잘못된 것은 없는 지 등 신뢰성 있는 데이터를 보장하는 역할을 담당

>계층 3, 네트워크 계층 (Network Layer)
: IP주소를 사용하여 네트워크 데이터를 어느 컴퓨터로 보낼 지 담당
-IP 주소는 컴퓨터당 하나가 부여되지만 중간에 바뀔 수 있으며, 소프트웨어적으로 존재하는 개념
ex) 라우터

>계층 2, 데이터 링크 계층 (Data Link Layer)
: 네트워크 카드의 MAC 주소를 사용해 네트워크 데이터를 어느 컴퓨터로 보낼 지를 담당
-MAC 주소는 랜카드당 하나가 존재
-IP 주소와는 다르게 변하지 않으며 하드웨어 자체에 포함되는 개념

>계층 1, 물리 계층 (Physical)
: 디지털 데이터를 아날로그적인 전기적 신호로 변환하여 네트워크 전선에 흘려보냄
-아날로그 신호를 디지털 신호로 바꾸는 역할도 함


## TCP/IP 4계층 모델
---

>계층 4, 응용 계층 (Application Layer)
: OSI 7계층 모델의 7,6,5(용용, 표현, 세션) 계층 기능을 담당
-HTTP, Telnet, SSH, FTP와 같은 프로토콜이 여기에서 사용됨

>계층 3, 전송 계층 (Transport Layer)
: OSI 7계층 모델의 4(전송) 계층과 같습니다. 프로세스 간의 신뢰성 있는 데이터 전송을 담당
-TCP, UDP와 같은 프로토콜이 여기에서 사용됨

>계층 2, 인터넷 계층 (Internet Layer)
: OSI 7 계층 모델의 3(네트워크) 계층과 같음
-컴퓨터 간 라우팅을 담당

>계층 1, 네트워크 인터페이스 계층 (Network Interface Layer)
: OSI 7계층 모델의 2, 1(데이터 링크, 물리) 계층과 같음
-네트워크 통신의 물리적인 부분들을 주로 포함


## HTTP vs HTTPS
---

1) HTTP: 텍스트 문서를 주고 받기 위해 만들어진 프로토콜
-보안이 취약하여 통신 과정에도 응용 계층의 데이터를 암호화할 필요성이 생김

2) HTTPS
:보안의 역할을 하는 SSL 계층을 기반으로 하는 HTTP 통신
-내용을 암호화하고 복호화하는 로직이 추가되었으므로 기존보다 통신 로직이 좀 더 복잡해짐








